# Brand Safety Timeline

AI-powered video content analysis for brand safety compliance. Built with Next.js and powered by Memories.ai.

## ğŸ¯ Features

- **Instant Video Analysis**: Upload videos and get brand safety analysis in seconds
- **Interactive Timeline**: Visual timeline with clickable risk markers  
- **GARM Categories**: Detects profanity, violence, sexual content, drugs/alcohol, hate speech, sensitive issues, and sponsorship
- **Multiple Export Formats**: Export reports as JSON, CSV, or SRT subtitle files
- **Real-time Processing**: Live progress indicators and instant results

## ğŸš€ Quick Setup

### 1. Install Dependencies

```bash
npm install
```

### 2. Configure Memories.ai API

1. Get your API key from [Memories.ai](https://mavi-backend.memories.ai)
2. Create account â†’ API section â†’ Create new API key
3. Copy `.env.example` to `.env.local`:

```bash
cp .env.example .env.local
```

4. Add your API key to `.env.local`:

```env
MEMORIES_API_KEY=your_memories_ai_api_key_here
```

### 3. Run Development Server

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000) to see the application.

## ğŸ“ Usage

1. **Upload Video**: Drag and drop a video file (MP4, AVI, MOV, etc.) up to 100MB
2. **Wait for Analysis**: The system will upload and analyze your video using AI
3. **Review Timeline**: Click on risk markers to jump to specific moments
4. **Export Results**: Download analysis reports in JSON, CSV, or SRT format

## ğŸ› ï¸ Tech Stack

- **Frontend**: Next.js 15, React 19, TypeScript, Tailwind CSS
- **Backend**: Next.js API Routes
- **AI Analysis**: Memories.ai (video indexing, search, transcription)
- **File Handling**: react-dropzone
- **Deployment**: Vercel-ready

## ğŸ“Š Risk Categories (GARM Standards)

- ğŸ¤¬ **Profanity**: Explicit language and swearing
- ğŸ’‹ **Sexual Content**: Adult material and suggestive content  
- ğŸº **Drugs & Alcohol**: Substance use and consumption
- ğŸ”« **Violence**: Weapons, fighting, and aggressive behavior
- âš ï¸ **Hate Speech**: Discriminatory language
- ğŸ—ï¸ **Sensitive Issues**: Political content and controversial topics
- ğŸ“£ **Sponsorship**: Undisclosed advertising content

## ğŸ—ï¸ Project Structure

```
src/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/memories/          # API routes for Memories.ai integration
â”‚   â”‚   â”œâ”€â”€ upload/           # Video upload endpoint
â”‚   â”‚   â”œâ”€â”€ status/           # Processing status check
â”‚   â”‚   â”œâ”€â”€ analyze/          # Brand safety analysis
â”‚   â”‚   â””â”€â”€ export/           # Report export (JSON/CSV/SRT)
â”‚   â”œâ”€â”€ globals.css           # Global styles
â”‚   â”œâ”€â”€ layout.tsx            # Root layout
â”‚   â””â”€â”€ page.tsx              # Main application page
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ VideoPlayer.tsx       # Video player with timeline
â”‚   â””â”€â”€ UploadZone.tsx        # File upload component
â””â”€â”€ lib/
    â”œâ”€â”€ memoriesClient.ts     # Memories.ai API wrapper
    â””â”€â”€ riskCategories.ts     # GARM category definitions
```

## ğŸš€ Deploy on Vercel

1. Connect your repository to Vercel
2. Add environment variable: `MEMORIES_API_KEY`
3. Deploy automatically

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https://github.com/your-username/brand-safety-timeline)

## ğŸª Hackathon Demo Script

1. **Problem**: "Manual brand safety review takes 3+ hours per video"
2. **Upload**: Drop in sample ad video â†’ processing spinner  
3. **Magic Moment**: Timeline populates with risk markers instantly
4. **Interaction**: Click marker â†’ jump to exact timestamp â†’ show evidence
5. **Value**: "Export report â†’ hand to editor â†’ save 3 hours"

## ğŸ“„ License

Built for AI Engine Hackathon. Open source MIT license.
